{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pylab as P\n",
    "\n",
    "import quantipy as qp\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import ttest_ind\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from pylab import rcParams\n",
    "\n",
    "import math\n",
    "from math import sqrt\n",
    "from scipy.stats import t\n",
    "\n",
    "import operator\n",
    "import statistics\n",
    "\n",
    "from pprint import pprint\n",
    "from dill.source import getsource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = pd.read_csv('g1-updated.csv')\n",
    "g2 = pd.read_csv('g2-updated.csv')\n",
    "g3 = pd.read_csv('g3-updated.csv')\n",
    "aus = pd.read_csv('combinedaus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the next 3 lines take out 'Timestamp', 'race_p1', 'race_p2', and 'raised_in', because our groups are mutually exclusive anyway so these columns are redundant now\n",
    "g1 = pd.concat([g1.iloc[:,1:4], g1.iloc[:,7:]], axis=1, sort=False)\n",
    "g2 = pd.concat([g2.iloc[:,1:4], g2.iloc[:,7:]], axis=1, sort=False)\n",
    "g3 = pd.concat([g3.iloc[:,1:4], g3.iloc[:,7:]], axis=1, sort=False)\n",
    "g0 = g1.append([g2, g3], ignore_index=True, sort=False)\n",
    "\n",
    "## rename a column in df aus\n",
    "aus = aus.rename(index=str, columns={\"Photo Id\": \"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_neu(g_num):\n",
    "    return pd.concat([g_num.iloc[:,:3], g_num.iloc[:].filter(regex='neutral')], axis=1, sort=False)\n",
    "\n",
    "def con_ang(g_num):\n",
    "    return pd.concat([g_num.iloc[:,:3], g_num.iloc[:].filter(regex='anger')], axis=1, sort=False)\n",
    "\n",
    "def con_neu_ang(g_num):\n",
    "    return pd.concat([g_num.iloc[:,:3], g_num.iloc[:].filter(regex='neutral'), g_num.iloc[:].filter(regex='anger')], axis=1, sort=False)\n",
    "\n",
    "def con_c(g_num):\n",
    "    return pd.concat([g_num.iloc[:,:3], g_num.iloc[:].filter(regex='cf'), g_num.iloc[:].filter(regex='cm')], axis=1, sort=False)\n",
    "\n",
    "def con_sa(g_num):\n",
    "    return pd.concat([g_num.iloc[:,:3], g_num.iloc[:].filter(regex='saf'), g_num.iloc[:].filter(regex='sam')], axis=1, sort=False)\n",
    "\n",
    "def g_c(g_num): return g_num.loc[g_num['race'] == 'White']\n",
    "\n",
    "def g_sa(g_num): return g_num.loc[g_num['race'] == 'South Asian']\n",
    "\n",
    "########################\n",
    "def con_PAD(g_num):\n",
    "    return pd.concat([g_num.iloc[:,:3], g_num.iloc[:].filter(regex='pleasure'), g_num.iloc[:].filter(regex='arousal'), g_num.iloc[:].filter(regex='dominance')], axis=1, sort=False)\n",
    "\n",
    "def con_P(g_num):\n",
    "    return pd.concat([g_num.iloc[:,:3], g_num.iloc[:].filter(regex='pleasure')], axis=1, sort=False)\n",
    "\n",
    "def con_A(g_num):\n",
    "    return pd.concat([g_num.iloc[:,:3], g_num.iloc[:].filter(regex='arousal')], axis=1, sort=False)\n",
    "\n",
    "def con_D(g_num):\n",
    "    return pd.concat([g_num.iloc[:,:3], g_num.iloc[:].filter(regex='dominance')], axis=1, sort=False)\n",
    "\n",
    "def con_f(g_num): return pd.concat([g_num.iloc[:,:3], g_num.iloc[:].filter(regex='cf'), g_num.iloc[:].filter(regex='saf')], axis=1, sort=False)\n",
    "\n",
    "def con_m(g_num): return pd.concat([g_num.iloc[:,:3], g_num.iloc[:].filter(regex='cm'), g_num.iloc[:].filter(regex='sam')], axis=1, sort=False)\n",
    "\n",
    "def con_neu2(g_num):\n",
    "    return pd.concat([g_num.iloc[:,:3], g_num.iloc[:].filter(regex='_n_')], axis=1, sort=False)\n",
    "def con_ang2(g_num):\n",
    "    return pd.concat([g_num.iloc[:,:3], g_num.iloc[:].filter(regex='_a_')], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_na = con_neu_ang(g0)\n",
    "g_pad = con_PAD(g0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL ratings\n",
    "# output = dataframe\n",
    "\n",
    "#####################################################\n",
    "# all rate all angry & neutral images\n",
    "def all_rate_all(g_num): return con_neu_ang(g_num)\n",
    "\n",
    "# all rate all neutral images\n",
    "def all_rate_all_neutral(g_num): return con_neu(g_num)\n",
    "\n",
    "# all rate all angry images\n",
    "def all_rate_all_anger(g_num): return con_ang(g_num)\n",
    "\n",
    "#####################################################\n",
    "# all rate angry & neutral caucasian images\n",
    "def all_rate_c(g_num): return con_c(con_neu_ang(g_num))\n",
    "\n",
    "# all rate neutral caucasian images\n",
    "def all_rate_c_neutral(g_num): return con_c(con_neu(g_num))\n",
    "\n",
    "# caucasians rate angry caucasian images\n",
    "def all_rate_c_anger(g_num): return con_c(con_ang(g_num))\n",
    "\n",
    "#####################################################\n",
    "# all rate angry & neutral south asian images\n",
    "def all_rate_sa(g_num): return con_sa(con_neu_ang(g_num))\n",
    "\n",
    "# all rate neutral south asian images\n",
    "def all_rate_sa_neutral(g_num): return con_sa(con_neu(g_num))\n",
    "\n",
    "# all rate angry south asian images\n",
    "def all_rate_sa_anger(g_num): return con_sa(con_ang(g_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RACE rates ALL\n",
    "# output = dataframe\n",
    "\n",
    "# caucasians rate angry & neutral images\n",
    "def c_rate_all(g_num): return g_c(con_neu_ang(g_num))\n",
    "\n",
    "# south asians rate angry & neutral images\n",
    "def sa_rate_all(g_num): return g_sa(con_neu_ang(g_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CAUCASIANS rate CAUCASIANS\n",
    "# output = dataframe\n",
    "\n",
    "# caucasians rate angry & neutral caucasian images\n",
    "def c_rate_c(g_num): return g_c(con_c(con_neu_ang(g_num)))\n",
    "\n",
    "# caucasians rate neutral caucasian images\n",
    "def c_rate_c_neutral(g_num): return g_c(con_c(con_neu(g_num)))\n",
    "\n",
    "# caucasians rate angry caucasian images\n",
    "def c_rate_c_anger(g_num): return g_c(con_c(con_ang(g_num)))\n",
    "\n",
    "# PAD\n",
    "def c_rate_c_p(g_num): return g_c(con_c(con_P(g_num)))\n",
    "def c_rate_c_neutral_p(g_num): return g_c(con_c(con_neu2(con_P(g_num))))\n",
    "def c_rate_c_anger_p(g_num): return g_c(con_c(con_ang2(con_P(g_num))))\n",
    "\n",
    "def c_rate_c_a(g_num): return g_c(con_c(con_A(g_num)))\n",
    "def c_rate_c_neutral_a(g_num): return g_c(con_c(con_neu2(con_A(g_num))))\n",
    "def c_rate_c_anger_a(g_num): return g_c(con_c(con_ang2(con_A(g_num))))\n",
    "\n",
    "def c_rate_c_d(g_num): return g_c(con_c(con_D(g_num)))\n",
    "def c_rate_c_neutral_d(g_num): return g_c(con_c(con_neu2(con_D(g_num))))\n",
    "def c_rate_c_anger_d(g_num): return g_c(con_c(con_ang2(con_D(g_num))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAUCASIANS rate SOUTH ASIANS\n",
    "# output = dataframe\n",
    "\n",
    "# caucasians rate angry & neutral south asian images\n",
    "def c_rate_sa(g_num): return g_c(con_sa(con_neu_ang(g_num)))\n",
    "\n",
    "# caucasians rate neutral south asian images\n",
    "def c_rate_sa_neutral(g_num): return g_c(con_sa(con_neu(g_num)))\n",
    "\n",
    "# caucasians rate angry south asian images\n",
    "def c_rate_sa_anger(g_num): return g_c(con_sa(con_ang(g_num)))\n",
    "\n",
    "# PAD\n",
    "def c_rate_sa_p(g_num): return g_c(con_sa(con_P(g_num)))\n",
    "def c_rate_sa_neutral_p(g_num): return g_c(con_sa(con_neu2(con_P(g_num))))\n",
    "def c_rate_sa_anger_p(g_num): return g_c(con_sa(con_ang2(con_P(g_num))))\n",
    "\n",
    "def c_rate_sa_a(g_num): return g_c(con_sa(con_A(g_num)))\n",
    "def c_rate_sa_neutral_a(g_num): return g_c(con_sa(con_neu2(con_A(g_num))))\n",
    "def c_rate_sa_anger_a(g_num): return g_c(con_sa(con_ang2(con_A(g_num))))\n",
    "\n",
    "def c_rate_sa_d(g_num): return g_c(con_sa(con_D(g_num)))\n",
    "def c_rate_sa_neutral_d(g_num): return g_c(con_sa(con_neu2(con_D(g_num))))\n",
    "def c_rate_sa_anger_d(g_num): return g_c(con_sa(con_ang2(con_D(g_num))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOUTH ASIANS rate CAUCASIANS\n",
    "# output = dataframe\n",
    "\n",
    "# south asians rate angry & neutral caucasian images\n",
    "def sa_rate_c(g_num): return g_sa(con_c(con_neu_ang(g_num)))\n",
    "\n",
    "# south asians rate neutral caucasian images\n",
    "def sa_rate_c_neutral(g_num): return g_sa(con_c(con_neu(g_num)))\n",
    "\n",
    "# south asians rate angry caucasian images\n",
    "def sa_rate_c_anger(g_num): return g_sa(con_c(con_ang(g_num)))\n",
    "\n",
    "# PAD\n",
    "def sa_rate_c_p(g_num): return g_sa(con_c(con_P(g_num)))\n",
    "def sa_rate_c_neutral_p(g_num): return g_sa(con_c(con_neu2(con_P(g_num))))\n",
    "def sa_rate_c_anger_p(g_num): return g_sa(con_c(con_ang2(con_P(g_num))))\n",
    "\n",
    "def sa_rate_c_a(g_num): return g_sa(con_c(con_A(g_num)))\n",
    "def sa_rate_c_neutral_a(g_num): return g_sa(con_c(con_neu2(con_A(g_num))))\n",
    "def sa_rate_c_anger_a(g_num): return g_sa(con_c(con_ang2(con_A(g_num))))\n",
    "\n",
    "def sa_rate_c_d(g_num): return g_sa(con_c(con_D(g_num)))\n",
    "def sa_rate_c_neutral_d(g_num): return g_sa(con_c(con_neu2(con_D(g_num))))\n",
    "def sa_rate_c_anger_d(g_num): return g_sa(con_c(con_ang2(con_D(g_num))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOUTH ASIANS rate SOUTH ASIANS\n",
    "# output = dataframe\n",
    "\n",
    "# south asians rate angry & neutral south asian images\n",
    "def sa_rate_sa(g_num): return g_sa(con_sa(con_neu_ang(g_num)))\n",
    "\n",
    "# caucasians rate neutral caucasian images\n",
    "def sa_rate_sa_neutral(g_num): return g_sa(con_sa(con_neu(g_num)))\n",
    "\n",
    "# caucasians rate angry caucasian images\n",
    "def sa_rate_sa_anger(g_num): return g_sa(con_sa(con_ang(g_num)))\n",
    "\n",
    "# PAD\n",
    "def sa_rate_sa_p(g_num): return g_sa(con_sa(con_P(g_num)))\n",
    "def sa_rate_sa_neutral_p(g_num): return g_sa(con_sa(con_neu2(con_P(g_num))))\n",
    "def sa_rate_sa_anger_p(g_num): return g_sa(con_sa(con_ang2(con_P(g_num))))\n",
    "\n",
    "def sa_rate_sa_a(g_num): return g_sa(con_sa(con_A(g_num)))\n",
    "def sa_rate_sa_neutral_a(g_num): return g_sa(con_sa(con_neu2(con_A(g_num))))\n",
    "def sa_rate_sa_anger_a(g_num): return g_sa(con_sa(con_ang2(con_A(g_num))))\n",
    "\n",
    "def sa_rate_sa_d(g_num): return g_sa(con_sa(con_D(g_num)))\n",
    "def sa_rate_sa_neutral_d(g_num): return g_sa(con_sa(con_neu2(con_D(g_num))))\n",
    "def sa_rate_sa_anger_d(g_num): return g_sa(con_sa(con_ang2(con_D(g_num))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split lists into low/med/high scores\n",
    "lof_1 = [all_rate_all, all_rate_c, all_rate_sa,\n",
    "         c_rate_all, c_rate_c, c_rate_sa,\n",
    "         sa_rate_all, sa_rate_c, sa_rate_sa]\n",
    "\n",
    "def list_of_t(g_num):\n",
    "    list_of_t = []\n",
    "    for eachfn in lof_1:\n",
    "        for eachcol in eachfn(g_num).iloc[:,3:]:\n",
    "            # creates a tuple of (who rated?, whose photo, median score)\n",
    "            list_of_t.append((eachfn.__name__, eachcol, eachfn(g_num)[eachcol].mean()))\n",
    "    return list_of_t\n",
    "\n",
    "def x_rated_all(who_rated):\n",
    "    new_l = []\n",
    "    for each in list_of_t(g_na):\n",
    "        if each[0] == who_rated:\n",
    "            new_l.append(each)\n",
    "    sorted_scores = sorted(new_l, key=lambda tup:(-tup[2], tup[0]))\n",
    "    return sorted_scores\n",
    "\n",
    "def split_ratings(who_rated):\n",
    "    sorted_scores = x_rated_all(who_rated)\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    list3 = []\n",
    "    for each in range(len(sorted_scores)):\n",
    "        if sorted_scores[each][2] >= 7:\n",
    "            list1.append((sorted_scores[each][1], sorted_scores[each][2]))\n",
    "        elif sorted_scores[each][2] <= 3:\n",
    "            list3.append((sorted_scores[each][1], sorted_scores[each][2]))\n",
    "        else:\n",
    "            list2.append((sorted_scores[each][1], sorted_scores[each][2]))\n",
    "    pprint(list1)\n",
    "    print('')\n",
    "    pprint(list2)\n",
    "    print('')\n",
    "    pprint(list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_ratings('all_rate_all')\n",
    "# split_ratings('c_rate_all')\n",
    "# split_ratings('sa_rate_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating the t-test for two independent samples\n",
    "def ind_ttest(data1, data2, alpha):\n",
    "    # calculate means\n",
    "    try:\n",
    "        mean1, mean2 = statistics.mean(data1), statistics.mean(data2)\n",
    "    except:\n",
    "        mean1, mean2 = data1.mean(), data2.mean()\n",
    "    # calculate sample standard deviations\n",
    "    std1, std2 = np.std(data1, ddof=1), np.std(data2, ddof=1)\n",
    "    # calculate standard errors\n",
    "    n1, n2 = len(data1), len(data2)\n",
    "    se1, se2 = std1/sqrt(n1), std2/sqrt(n2)\n",
    "    # standard error on the difference between the samples\n",
    "    sed = sqrt(se1**2.0 + se2**2.0)\n",
    "    # calculate the t statistic\n",
    "    t_stat = (mean1 - mean2) / sed\n",
    "    # degrees of freedom\n",
    "    df = len(data1) + len(data2) - 2\n",
    "    # calculate the critical value\n",
    "    cv = t.ppf(1.0 - alpha, df)\n",
    "    # calculate the p-value\n",
    "    p = (1.0 - t.cdf(abs(t_stat), df)) * 2.0\n",
    "    # return everything\n",
    "    return t_stat, df, cv, std1, std2, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list of images of caucasians\n",
    "loi_c = con_c(g_na).iloc[:,3:].columns.values.tolist()\n",
    "# list of images of south asians\n",
    "loi_sa = con_sa(g_na).iloc[:,3:].columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return list of values from dataframe\n",
    "def list_df_vals(fn, g_num, string):\n",
    "    x = []\n",
    "    for eachcol in fn(g_num):\n",
    "        if eachcol.startswith(string):\n",
    "            for eachnum in fn(g_num)[eachcol]:\n",
    "                if not math.isnan(eachnum):\n",
    "                    x.append(eachnum)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings for caucasians by caucasians\n",
    "c_c = list_df_vals(c_rate_c, g_na, 'c')\n",
    "c_c_neu = list_df_vals(c_rate_c_neutral, g_na, 'c')\n",
    "c_c_ang = list_df_vals(c_rate_c_anger, g_na, 'c')\n",
    "\n",
    "# ratings for south asians by caucians\n",
    "c_sa = list_df_vals(c_rate_sa, g_na, 'sa')\n",
    "c_sa_neu = list_df_vals(c_rate_sa_neutral, g_na, 'sa')\n",
    "c_sa_ang = list_df_vals(c_rate_sa_anger, g_na, 'sa')\n",
    "\n",
    "# ratings for caucasians by south asians\n",
    "sa_c = list_df_vals(sa_rate_c, g_na, 'c')\n",
    "sa_c_neu = list_df_vals(sa_rate_c_neutral, g_na, 'c')\n",
    "sa_c_ang = list_df_vals(sa_rate_c_anger, g_na, 'c')\n",
    "\n",
    "# ratings for south asians by south asians\n",
    "sa_sa = list_df_vals(sa_rate_sa, g_na, 'sa')\n",
    "sa_sa_neu = list_df_vals(sa_rate_sa_neutral, g_na, 'sa')\n",
    "sa_sa_ang = list_df_vals(sa_rate_sa_anger, g_na, 'sa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAD scores for groups listed above\n",
    "c_c_p = list_df_vals(c_rate_c_p, g_pad, 'c')\n",
    "c_c_p_neu = list_df_vals(c_rate_c_neutral_p, g_pad, 'c')\n",
    "c_c_p_ang = list_df_vals(c_rate_c_anger_p, g_pad, 'c')\n",
    "\n",
    "c_c_a = list_df_vals(c_rate_c_a, g_pad, 'c')\n",
    "c_c_a_neu = list_df_vals(c_rate_c_neutral_a, g_pad, 'c')\n",
    "c_c_a_ang = list_df_vals(c_rate_c_anger_a, g_pad, 'c')\n",
    "\n",
    "c_c_d = list_df_vals(c_rate_c_d, g_pad, 'c')\n",
    "c_c_d_neu = list_df_vals(c_rate_c_neutral_d, g_pad, 'c')\n",
    "c_c_d_ang = list_df_vals(c_rate_c_anger_d, g_pad, 'c')\n",
    "\n",
    "#\n",
    "c_sa_p = list_df_vals(c_rate_sa_p, g_pad, 'sa')\n",
    "c_sa_p_neu = list_df_vals(c_rate_sa_neutral_p, g_pad, 'sa')\n",
    "c_sa_p_ang = list_df_vals(c_rate_sa_anger_p, g_pad, 'sa')\n",
    "\n",
    "c_sa_a = list_df_vals(c_rate_sa_a, g_pad, 'sa')\n",
    "c_sa_a_neu = list_df_vals(c_rate_sa_neutral_a, g_pad, 'sa')\n",
    "c_sa_a_ang = list_df_vals(c_rate_sa_anger_a, g_pad, 'sa')\n",
    "\n",
    "c_sa_d = list_df_vals(c_rate_sa_d, g_pad, 'sa')\n",
    "c_sa_d_neu = list_df_vals(c_rate_sa_neutral_d, g_pad, 'sa')\n",
    "c_sa_d_ang = list_df_vals(c_rate_sa_anger_d, g_pad, 'sa')\n",
    "\n",
    "#\n",
    "sa_c_p = list_df_vals(sa_rate_c_p, g_pad, 'c')\n",
    "sa_c_p_neu = list_df_vals(sa_rate_c_neutral_p, g_pad, 'c')\n",
    "sa_c_p_ang = list_df_vals(sa_rate_c_anger_p, g_pad, 'c')\n",
    "\n",
    "sa_c_a = list_df_vals(sa_rate_c_a, g_pad, 'c')\n",
    "sa_c_a_neu = list_df_vals(sa_rate_c_neutral_a, g_pad, 'c')\n",
    "sa_c_a_ang = list_df_vals(sa_rate_c_anger_a, g_pad, 'c')\n",
    "\n",
    "sa_c_d = list_df_vals(sa_rate_c_d, g_pad, 'c')\n",
    "sa_c_d_neu = list_df_vals(sa_rate_c_neutral_d, g_pad, 'c')\n",
    "sa_c_d_ang = list_df_vals(sa_rate_c_anger_d, g_pad, 'c')\n",
    "\n",
    "#\n",
    "sa_sa_p = list_df_vals(sa_rate_sa_p, g_pad, 'sa')\n",
    "sa_sa_p_neu = list_df_vals(sa_rate_sa_neutral_p, g_pad, 'sa')\n",
    "sa_sa_p_ang = list_df_vals(sa_rate_sa_anger_p, g_pad, 'sa')\n",
    "\n",
    "sa_sa_a = list_df_vals(sa_rate_sa_a, g_pad, 'sa')\n",
    "sa_sa_a_neu = list_df_vals(sa_rate_sa_neutral_a, g_pad, 'sa')\n",
    "sa_sa_a_ang = list_df_vals(sa_rate_sa_anger_a, g_pad, 'sa')\n",
    "\n",
    "sa_sa_d = list_df_vals(sa_rate_sa_d, g_pad, 'sa')\n",
    "sa_sa_d_neu = list_df_vals(sa_rate_sa_neutral_d, g_pad, 'sa')\n",
    "sa_sa_d_ang = list_df_vals(sa_rate_sa_anger_d, g_pad, 'sa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings for males & females\n",
    "f_f_1 = list_df_vals(con_f, g_na.loc[g_na['gender'] == 'Female'], 'c')\n",
    "f_f_2 = list_df_vals(con_f, g_na.loc[g_na['gender'] == 'Female'], 'sa')\n",
    "f_f_3 = []\n",
    "for each in f_f_1:\n",
    "    f_f_3.append(each)\n",
    "for each in f_f_2:\n",
    "    f_f_3.append(each)\n",
    "\n",
    "m_m_1 = list_df_vals(con_m, g_na.loc[g_na['gender'] == 'Male'], 'c')\n",
    "m_m_2 = list_df_vals(con_m, g_na.loc[g_na['gender'] == 'Male'], 'sa')\n",
    "m_m_3 = []\n",
    "for each in m_m_1:\n",
    "    m_m_3.append(each)\n",
    "for each in m_m_2:\n",
    "    m_m_3.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]\n",
    "\n",
    "# Now we compute significance BETWEEN groups\n",
    "# RESULT: Both caucasians and south asians rate SOUTH ASIAN (neutral & angry), and (angry) photos very differently.\n",
    "# Output below\n",
    "lovalues_between = [(c_c, sa_c), (c_c_neu, sa_c_neu), (c_c_ang, sa_c_ang),\n",
    "                    (c_sa, sa_sa), (c_sa_neu, sa_sa_neu), (c_sa_ang, sa_sa_ang)]\n",
    "\n",
    "# Now we compute significance between groups on the PAD scale\n",
    "# Result: Dominance scales were significantly different between races.\n",
    "#         All dominance scores except for when comparing the South Asian neutral group were significant.\n",
    "# Output below\n",
    "lovalues_pad = [(c_c_p, sa_c_p), (c_c_p_neu, sa_c_p_neu), (c_c_p_ang, sa_c_p_ang),\n",
    "                (c_sa_p, sa_sa_p), (c_sa_p_neu, sa_sa_p_neu), (c_sa_p_ang, sa_sa_p_ang),\n",
    "                \n",
    "                (c_c_a, sa_c_a), (c_c_a_neu, sa_c_a_neu), (c_c_a_ang, sa_c_a_ang),\n",
    "                (c_sa_a, sa_sa_a), (c_sa_a_neu, sa_sa_a_neu), (c_sa_a_ang, sa_sa_a_ang),\n",
    "                \n",
    "                (c_c_d, sa_c_d), (c_c_d_neu, sa_c_d_neu), (c_c_d_ang, sa_c_d_ang),\n",
    "                (c_sa_d, sa_sa_d), (c_sa_d_neu, sa_sa_d_neu), (c_sa_d_ang, sa_sa_d_ang)]\n",
    "\n",
    "# Now we compute significance between gender\n",
    "# Result: No significance\n",
    "# Output below\n",
    "lovalues_gender = [(f_f_1, f_f_2), (m_m_1, m_m_2),\n",
    "                   (f_f_1, m_m_1), (f_f_2, m_m_2),\n",
    "                   (f_f_3, m_m_3)]\n",
    "\n",
    "def print_sig(lov):\n",
    "    for each in lov:\n",
    "        print(str(namestr(each[0], globals())[0].upper()) + str(' vs ') + str(namestr(each[1], globals())[0].upper()) + ':')\n",
    "        print('P-value: ' + str(round(ind_ttest(each[0], each[1], .1)[-1], 3)))\n",
    "        if ind_ttest(each[0], each[1], .1)[-1] < .1:\n",
    "            print('*************** Significant! ***************')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_C vs SA_C:\n",
      "P-value: 0.764\n",
      "\n",
      "C_C_NEU vs SA_C_NEU:\n",
      "P-value: 0.658\n",
      "\n",
      "C_C_ANG vs SA_C_ANG:\n",
      "P-value: 0.993\n",
      "\n",
      "C_SA vs SA_SA:\n",
      "P-value: 0.005\n",
      "*************** Significant! ***************\n",
      "\n",
      "C_SA_NEU vs SA_SA_NEU:\n",
      "P-value: 0.146\n",
      "\n",
      "C_SA_ANG vs SA_SA_ANG:\n",
      "P-value: 0.007\n",
      "*************** Significant! ***************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# significance when rating south asians\n",
    "print_sig(lovalues_between)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_C_P vs SA_C_P:\n",
      "P-value: 0.655\n",
      "\n",
      "C_C_P_NEU vs SA_C_P_NEU:\n",
      "P-value: 0.972\n",
      "\n",
      "C_C_P_ANG vs SA_C_P_ANG:\n",
      "P-value: 0.501\n",
      "\n",
      "C_SA_P vs SA_SA_P:\n",
      "P-value: 0.301\n",
      "\n",
      "C_SA_P_NEU vs SA_SA_P_NEU:\n",
      "P-value: 0.35\n",
      "\n",
      "C_SA_P_ANG vs SA_SA_P_ANG:\n",
      "P-value: 0.543\n",
      "\n",
      "C_C_A vs SA_C_A:\n",
      "P-value: 0.983\n",
      "\n",
      "C_C_A_NEU vs SA_C_A_NEU:\n",
      "P-value: 0.466\n",
      "\n",
      "C_C_A_ANG vs SA_C_A_ANG:\n",
      "P-value: 0.502\n",
      "\n",
      "C_SA_A vs SA_SA_A:\n",
      "P-value: 0.682\n",
      "\n",
      "C_SA_A_NEU vs SA_SA_A_NEU:\n",
      "P-value: 0.239\n",
      "\n",
      "C_SA_A_ANG vs SA_SA_A_ANG:\n",
      "P-value: 0.61\n",
      "\n",
      "C_C_D vs SA_C_D:\n",
      "P-value: 0.001\n",
      "*************** Significant! ***************\n",
      "\n",
      "C_C_D_NEU vs SA_C_D_NEU:\n",
      "P-value: 0.056\n",
      "*************** Significant! ***************\n",
      "\n",
      "C_C_D_ANG vs SA_C_D_ANG:\n",
      "P-value: 0.005\n",
      "*************** Significant! ***************\n",
      "\n",
      "C_SA_D vs SA_SA_D:\n",
      "P-value: 0.015\n",
      "*************** Significant! ***************\n",
      "\n",
      "C_SA_D_NEU vs SA_SA_D_NEU:\n",
      "P-value: 0.13\n",
      "\n",
      "C_SA_D_ANG vs SA_SA_D_ANG:\n",
      "P-value: 0.042\n",
      "*************** Significant! ***************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# significance on dominance ratings\n",
    "print_sig(lovalues_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_F_1 vs F_F_2:\n",
      "P-value: 0.407\n",
      "\n",
      "M_M_1 vs M_M_2:\n",
      "P-value: 0.77\n",
      "\n",
      "F_F_1 vs M_M_1:\n",
      "P-value: 0.365\n",
      "\n",
      "F_F_2 vs M_M_2:\n",
      "P-value: 0.863\n",
      "\n",
      "F_F_3 vs M_M_3:\n",
      "P-value: 0.382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# no significance anywhere between gender\n",
    "print_sig(lovalues_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we compute significance WITHIN groups\n",
    "# We're checking to see if each race has a smaller spread of scores for their own race vs. the spread of scores for the other race scoring them\n",
    "# RESULT: No show that Caucasians have smaller standard deviations when comparing own race, or the same with South Asians\n",
    "\n",
    "def print_std(lov):\n",
    "    for each in lov:\n",
    "        print(str(namestr(each[0], globals())[0].upper()) + str(' vs ') + str(namestr(each[1], globals())[0].upper()) + ':')\n",
    "        print('Standard Deviations for both groups: ' +\n",
    "              str(round(ind_ttest(each[0], each[1], .1)[3], 4)) + ', ' +\n",
    "              str(round(ind_ttest(each[0], each[1], .1)[4], 4)))\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_C vs SA_C:\n",
      "Standard Deviations for both groups: 2.4256, 2.4303\n",
      "\n",
      "C_C_NEU vs SA_C_NEU:\n",
      "Standard Deviations for both groups: 2.1977, 2.0552\n",
      "\n",
      "C_C_ANG vs SA_C_ANG:\n",
      "Standard Deviations for both groups: 2.469, 2.6298\n",
      "\n",
      "C_SA vs SA_SA:\n",
      "Standard Deviations for both groups: 2.3647, 2.8724\n",
      "\n",
      "C_SA_NEU vs SA_SA_NEU:\n",
      "Standard Deviations for both groups: 2.1407, 2.7248\n",
      "\n",
      "C_SA_ANG vs SA_SA_ANG:\n",
      "Standard Deviations for both groups: 2.432, 2.7579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# standard deviation is not smaller within groups\n",
    "print_std(lovalues_between)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AUS\n",
    "\n",
    "# ALL SHOW 4/9/10 IN ANGRY\n",
    "# C SHOW 4 AT HIGH LEVELS OF ANGER (SA DO TOO, BUT LESS THAN C)\n",
    "# SA SHOW 10 A LOT IN ANGER (C DO TOO, BUT SIG. LESS THAN SA)\n",
    "# SA SHOW 9 A LOT IN ANGER (C DOESN'T)\n",
    "# SA SHOW 9+10 IN NEUTRAL (C DOESN'T)\n",
    "\n",
    "# TRADITIONAL ANGER = 4+5+7+23\n",
    "# BOTH SHOW 5 MORE IN NEUTRAL\n",
    "# BOTH SHOW 7, BUT NO INDIVIDUALS DO???\n",
    "# C SHOW 23 WWHEN ANGRY (SA DOESN'T)\n",
    "aus_c = aus.loc[aus['id'].str.contains('^c')]\n",
    "aus_sa = aus.loc[aus['id'].str.contains('^sa')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "au1_all_ang = aus.loc[aus['id'].str.contains('_a')][['id', ' AU01_r']]\n",
    "au1_c_ang = au1_all_ang[au1_all_ang['id'].str.contains('^c')][['id', ' AU01_r']]\n",
    "au1_sa_ang = au1_all_ang[au1_all_ang['id'].str.contains('^s')][['id', ' AU01_r']]\n",
    "\n",
    "au4_all_ang = aus.loc[aus['id'].str.contains('_a')][['id', ' AU04_r']]\n",
    "au4_c_ang = au4_all_ang[au4_all_ang['id'].str.contains('^c')][['id', ' AU04_r']]\n",
    "au4_sa_ang = au4_all_ang[au4_all_ang['id'].str.contains('^s')][['id', ' AU04_r']]\n",
    "\n",
    "au9_all_neu = aus.loc[aus['id'].str.contains('_n')][['id', ' AU09_r']]\n",
    "au9_c_neu = au9_all_neu[au9_all_neu['id'].str.contains('^c')][['id', ' AU09_r']]\n",
    "au9_sa_neu = au9_all_neu[au9_all_neu['id'].str.contains('^s')][['id', ' AU09_r']]\n",
    "\n",
    "au9_all_ang = aus.loc[aus['id'].str.contains('_a')][['id', ' AU09_r']]\n",
    "au9_c_ang = au9_all_ang[au9_all_ang['id'].str.contains('^c')][['id', ' AU09_r']]\n",
    "au9_sa_ang = au9_all_ang[au9_all_ang['id'].str.contains('^s')][['id', ' AU09_r']]\n",
    "\n",
    "au10_all_neu = aus.loc[aus['id'].str.contains('_n')][['id', ' AU10_r']]\n",
    "au10_c_neu = au10_all_neu[au10_all_neu['id'].str.contains('^c')][['id', ' AU10_r']]\n",
    "au10_sa_neu = au10_all_neu[au10_all_neu['id'].str.contains('^s')][['id', ' AU10_r']]\n",
    "\n",
    "au10_all_ang = aus.loc[aus['id'].str.contains('_a')][['id', ' AU10_r']]\n",
    "au10_c_ang = au10_all_ang[au10_all_ang['id'].str.contains('^c')][['id', ' AU10_r']]\n",
    "au10_sa_ang = au10_all_ang[au10_all_ang['id'].str.contains('^s')][['id', ' AU10_r']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found a number of significant differences for AU scores between races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09528735411469569"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AU04 on anger\n",
    "ind_ttest(au4_sa_ang[' AU04_r'].values.tolist(), au4_c_ang[' AU04_r'].values.tolist(), .1)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09931827408013394"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AU09 on anger\n",
    "ind_ttest(au9_sa_ang[' AU09_r'].values.tolist(), au9_c_ang[' AU09_r'].values.tolist(), .1)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0768044251124329"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AU10 on anger\n",
    "ind_ttest(au10_sa_ang[' AU10_r'].values.tolist(), au10_c_ang[' AU10_r'].values.tolist(), .1)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056070919781894935"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AU09 on neutral\n",
    "ind_ttest(au9_sa_neu[' AU09_r'].values.tolist(), au9_c_neu[' AU09_r'].values.tolist(), .1)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04328514417905027"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AU10 on neutral\n",
    "ind_ttest(au10_sa_neu[' AU10_r'].values.tolist(), au10_c_neu[' AU10_r'].values.tolist(), .1)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
